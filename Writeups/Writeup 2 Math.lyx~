#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
Graph Convolutional Network
\end_layout

\begin_layout Standard
A GraphSage GCN is trained across a number of timesteps (here indexed by
 
\begin_inset Formula $r$
\end_inset

) which progressively mix information from the embeddings of more and more
 distant neighbors.
 Creating these embeddings for a given timestep is a two-step process.
\end_layout

\begin_layout Standard
First, in the AGG step, the embeddings of the node's direct neighbors are
 aggregated.
 Using what is referred to as pool or pooling aggregation, for node 
\begin_inset Formula $h$
\end_inset

, with neighborhood 
\begin_inset Formula $N(i)$
\end_inset

, at timestep 
\begin_inset Formula $r$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{N(i)}^{(r)}=max[(\sigma(W_{pool}h_{j}^{(r-1)}+b),\forall j\in N(i)]
\]

\end_inset


\end_layout

\begin_layout Standard
meaning the neighboring embeddings from the previous timestep are fed through
 a fully connected neural network (weights 
\begin_inset Formula $W_{pool}$
\end_inset

, bias 
\begin_inset Formula $b$
\end_inset

, ReLU activation 
\begin_inset Formula $\sigma)$
\end_inset

, and then the elementwise maximum across the new neighbor representations
 is taken as the aggregated vector.
\end_layout

\begin_layout Standard
Next, during the update (or COMBINE) step, we concatenate the representation
 of our node of interest from the previous timestep with this aggregated
 vector, then apply another set of weights and activation to get a fully
 updated node representation.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{i}^{(r)}=\sigma(W^{(r)}*CONCAT[h_{i}^{(r-1)},h_{N(i)}^{(r)}])
\]

\end_inset


\end_layout

\begin_layout Standard
Note that in our implementation the update step has no activation 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
The operations for each timestep ultimately represent a layer of the neural
 network - a SAGEConv layer, of which we have 3.
 For our classification task, the last of these produces output of size
 9 (number of classes) for each node, while we use vectors of size 32 for
 intermediate 
\begin_inset Formula $h$
\end_inset

 values.
 The entire process is trained end-to-end with cross entropy loss.
 We perform weight decay at rate 5e-4 and train for 100 epochs at a learning
 rate of 0.01.
\end_layout

\begin_layout Section*
McNemar's Test
\end_layout

\begin_layout Standard
We make use of McNemar's Test to check for statistically significant differences
 between our models without NLP features (
\begin_inset Quotes eld
\end_inset

Model 2
\begin_inset Quotes erd
\end_inset

) and including NLP features (
\begin_inset Quotes eld
\end_inset

Model 3
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Standard
This test makes use of the following contingency table using counts over
 observations in our test dataset:
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model 3 Correct
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model 3 Incorrect
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Row Total
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model 2 Correct
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $b$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a+b$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model 2 Inorrect
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $c$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $d$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $c+d$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Column Total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a+c$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $b+d$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
Under the null hypothesis of identical performance, the marginal probabilities
 of each model being correct and incorrect are the same: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p_{a}+p_{b}=p_{a}+p_{c}
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
p_{c}+p_{d}=p_{b}+p_{d}
\]

\end_inset


\end_layout

\begin_layout Standard
which reduces to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H_{0}:p_{b}=p_{c}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H_{1}:p_{b}\neq p_{c}
\]

\end_inset


\end_layout

\begin_layout Standard
The test statistic is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{(b-c)^{2}}{b+c}\sim\chi_{1}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
(chi-squared with one degree of freedom) under 
\begin_inset Formula $H_{0}$
\end_inset

, for sufficiently large 
\begin_inset Formula $b$
\end_inset

 and 
\begin_inset Formula $c$
\end_inset

 (heuristically, at least 10 for each).
\end_layout

\begin_layout Standard
McNemar's test is paired, enabling us to effectively make comparisons between
 our models when they both face the same observations in the test dataset.
 At the same time, it operates on counts of the data (our counts correct
 and incorrect) and is non-parametric, without normality or other distributional
 assumptions.
 (Note: the test does still assume independence across observations, but
 it is difficult to perform testing without this.)
\end_layout

\end_body
\end_document
